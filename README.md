# ğŸ“˜ Modelo PI â€” DetecciÃ³n de Fraude con Streamlit

Este repositorio contiene todo el flujo necesario para procesar datos, generar un dataset final, entrenar un modelo de Machine Learning y desplegarlo mediante Streamlit para realizar predicciones en tiempo real.

El proyecto estÃ¡ diseÃ±ado para ser **100Â % reproducible**, permitiendo replicar el procesamiento, el anÃ¡lisis, el entrenamiento del modelo y su uso en producciÃ³n.

## ğŸ“‚ Estructura del proyecto

```
.
â”œâ”€â”€ RawData.xlsx                  # Datos originales en crudo
â”œâ”€â”€ salida_extendidafull3.csv    # Dataset procesado final
â”œâ”€â”€ raw-to-dataset.ipynb         # Notebook de procesamiento inicial
â”œâ”€â”€ eda-model-pi.ipynb           # Notebook de EDA + entrenamiento del modelo
â”œâ”€â”€ best_model_v1.joblib         # Modelo entrenado final
â”œâ”€â”€ app.py                       # AplicaciÃ³n en Streamlit para predicciones
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â””â”€â”€ README.md                    # DocumentaciÃ³n del repositorio
```

- **RawData.xlsx**: archivo de datos original en bruto.
- **raw-to-dataset.ipynb**: notebook que transforma los datos crudos en un dataset limpio y listo para anÃ¡lisis.
- **salida_extendidafull3.csv**: dataset resultante del procesamiento.
- **eda-model-pi.ipynb**: notebook donde se explora el dataset, se entrenan modelos y se guarda el mejor.
- **best_model_v1.joblib**: modelo de detecciÃ³n de fraude entrenado y guardado con `joblib`.
- **app.py**: aplicaciÃ³n de Streamlit que permite cargar archivos, generar predicciones y descargar resultados.
- **requirements.txt**: lista de dependencias para reproducir el entorno.

## ğŸ”„ Flujo del proyecto

El pipeline se divide en tres etapas principales:

### 1ï¸âƒ£ Procesamiento inicial de datos

- **Notebook**: `raw-to-dataset.ipynb`
- **Entrada**: `RawData.xlsx`
- **Salida**: `salida_extendidafull3.csv`

Este notebook realiza:
- Limpieza y estandarizaciÃ³n de datos.
- ConversiÃ³n de tipos de variable.
- Manejo de valores nulos y duplicados.
- IngenierÃ­a de caracterÃ­sticas (si aplica).
- ExportaciÃ³n del dataset procesado a CSV.

### 2ï¸âƒ£ AnÃ¡lisis exploratorio y entrenamiento del modelo

- **Notebook**: `eda-model-pi.ipynb`
- **Entrada**: `salida_extendidafull3.csv`
- **Salida**: `best_model_v1.joblib`

Incluye:
- AnÃ¡lisis exploratorio de los datos (EDA): distribuciones, correlaciones, outliers y balance de clases.
- PreparaciÃ³n de las features (`feature_names_in_`) y selecciÃ³n de variables.
- Entrenamiento de modelos supervisados.
- EvaluaciÃ³n del desempeÃ±o mediante mÃ©tricas como matriz de confusiÃ³n, ROC-AUC, F1-score y curva precisionâ€“recall.
- Guardado del mejor modelo entrenado en formato Joblib.

### 3ï¸âƒ£ AplicaciÃ³n en Streamlit para predicciones

- **Archivo**: `app.py`

CaracterÃ­sticas principales de la aplicaciÃ³n:
- Permite subir archivos CSV o Excel con detecciÃ³n automÃ¡tica de codificaciÃ³n y separadores.
- Valida que el archivo de entrada tenga las columnas requeridas por el modelo.
- Genera predicciones utilizando el modelo entrenado.
- Muestra la probabilidad de pertenecer a la clase de fraude (si el modelo lo permite).
- Agrega una columna de etiqueta legible (`0 = Normal`, `1 = Fraude`) para interpretar fÃ¡cilmente la predicciÃ³n.
- Presenta mÃ©tricas y grÃ¡ficos de resumen (casos totales, fraudes detectados, distribuciÃ³n por clase, topÂ 20 por probabilidad).
- Permite descargar los resultados en un archivo Excel (`.xlsx`) listo para su uso.

Para ejecutar la aplicaciÃ³n localmente:

```bash
# Instala las dependencias
pip install -r requirements.txt

# Ejecuta la app
streamlit run app.py
```

---

## ğŸ“¦ Reproducibilidad paso a paso

Siga estos pasos para reproducir el flujo completo:

1. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

2. **Procesar los datos crudos**
   Ejecute el notebook `raw-to-dataset.ipynb` para transformar `RawData.xlsx` en `salida_extendidafull3.csv`.

3. **Entrenar el modelo**
   Ejecute `eda-model-pi.ipynb` para realizar el EDA, entrenar el modelo y guardar `best_model_v1.joblib`.

4. **Iniciar la aplicaciÃ³n**
   ```bash
   streamlit run app.py
   ```

   Al iniciar la app, cargue un archivo que tenga las mismas columnas con las que se entrenÃ³ el modelo.

5. **Despliegue en Streamlit Cloud (opcional)**
   Este repositorio estÃ¡ listo para ser desplegado en [StreamlitÂ Cloud](https://share.streamlit.io/):
   - Conecte su cuenta de GitHub.
   - Seleccione este repositorio.
   - Defina `app.py` como archivo principal.
   - La plataforma instalarÃ¡ las dependencias y cargarÃ¡ el modelo automÃ¡ticamente.

---

## ğŸ§  Notas y buenas prÃ¡cticas

- Antes de entrenar un nuevo modelo, actualice y ejecute por completo los notebooks.
- AsegÃºrese de que el archivo de entrada usado en la app contenga exactamente las columnas con las que se entrenÃ³ el modelo; de lo contrario, se producirÃ¡ un error de validaciÃ³n.
- Mantenga el nombre del modelo coherente (`best_model_vX.joblib`). Si se crea una nueva versiÃ³n, actualice el nombre y el cÃ³digo de carga en `app.py`.
- Bloquee versiones especÃ­ficas de librerÃ­as en `requirements.txt` para asegurar la reproducibilidad.
- Para reproducir los grÃ¡ficos de EDA o personalizar la app, modifique directamente los notebooks y `app.py`.

---

## ğŸ“« Contacto

Si detecta problemas, desea proponer mejoras o contribuir al proyecto, no dude en crear un *Issue* o enviar un *Pull Request*. Â¡Gracias por su interÃ©s!
