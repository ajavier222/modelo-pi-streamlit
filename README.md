# üìò Modelo PI ‚Äî Detecci√≥n de Fraude con Streamlit

Este repositorio contiene todo el flujo necesario para procesar datos, generar un dataset final, entrenar un modelo de Machine Learning y desplegarlo mediante Streamlit para realizar predicciones en tiempo real.

El proyecto est√° dise√±ado para ser **100¬†% reproducible**, permitiendo replicar el procesamiento, el an√°lisis, el entrenamiento del modelo y su uso en producci√≥n.

## üìÇ Estructura del proyecto

```
.
‚îú‚îÄ‚îÄ RawData.xlsx                  # Datos originales en crudo
‚îú‚îÄ‚îÄ salida_extendidafull3.csv    # Dataset procesado final
‚îú‚îÄ‚îÄ raw-to-dataset.ipynb         # Notebook de procesamiento inicial
‚îú‚îÄ‚îÄ eda-model-pi.ipynb           # Notebook de EDA + entrenamiento del modelo
‚îú‚îÄ‚îÄ best_model_v1.joblib         # Modelo entrenado final
‚îú‚îÄ‚îÄ app.py                       # Aplicaci√≥n en Streamlit para predicciones
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                    # Documentaci√≥n del repositorio
```

- **RawData.xlsx**: archivo de datos original en bruto.
- **raw-to-dataset.ipynb**: notebook que transforma los datos crudos en un dataset limpio y listo para an√°lisis.
- **salida_extendidafull3.csv**: dataset resultante del procesamiento.
- **eda-model-pi.ipynb**: notebook donde se explora el dataset, se entrenan modelos y se guarda el mejor.
- **best_model_v1.joblib**: modelo de detecci√≥n de fraude entrenado y guardado con `joblib`.
- **app.py**: aplicaci√≥n de Streamlit que permite cargar archivos, generar predicciones y descargar resultados.
- **requirements.txt**: lista de dependencias para reproducir el entorno.

## üîÑ Flujo del proyecto

El pipeline se divide en tres etapas principales:

### 1Ô∏è‚É£ Procesamiento inicial de datos

- **Notebook**: `raw-to-dataset.ipynb`
- **Entrada**: `RawData.xlsx`
- **Salida**: `salida_extendidafull3.csv`

Este notebook realiza:
- Limpieza y estandarizaci√≥n de datos.
- Conversi√≥n de tipos de variable.
- Manejo de valores nulos y duplicados.
- Ingenier√≠a de caracter√≠sticas (si aplica).
- Exportaci√≥n del dataset procesado a CSV.

### 2Ô∏è‚É£ An√°lisis exploratorio y entrenamiento del modelo

- **Notebook**: `eda-model-pi.ipynb`
- **Entrada**: `salida_extendidafull3.csv`
- **Salida**: `best_model_v1.joblib`

Incluye:
- An√°lisis exploratorio de los datos (EDA): distribuciones, correlaciones, outliers y balance de clases.
- Preparaci√≥n de las features (`feature_names_in_`) y selecci√≥n de variables.
- Entrenamiento de modelos supervisados.
- Evaluaci√≥n del desempe√±o mediante m√©tricas como matriz de confusi√≥n, ROC-AUC, F1-score y curva precision‚Äìrecall.
- Guardado del mejor modelo entrenado en formato Joblib.

### 3Ô∏è‚É£ Aplicaci√≥n en Streamlit para predicciones

- **Archivo**: `app.py`

Caracter√≠sticas principales de la aplicaci√≥n:
- Permite subir archivos CSV o Excel con detecci√≥n autom√°tica de codificaci√≥n y separadores.
- Valida que el archivo de entrada tenga las columnas requeridas por el modelo.
- Genera predicciones utilizando el modelo entrenado.
- Muestra la probabilidad de pertenecer a la clase de fraude (si el modelo lo permite).
- Agrega una columna de etiqueta legible (`0 = Normal`, `1 = Fraude`) para interpretar f√°cilmente la predicci√≥n.
- Presenta m√©tricas y gr√°ficos de resumen (casos totales, fraudes detectados, distribuci√≥n por clase, top¬†20 por probabilidad).
- Permite descargar los resultados en un archivo Excel (`.xlsx`) listo para su uso.

Para ejecutar la aplicaci√≥n localmente:

```bash
# Instala las dependencias
pip install -r requirements.txt

# Ejecuta la app
streamlit run app.py
```

---

## üì¶ Reproducibilidad paso a paso

Siga estos pasos para reproducir el flujo completo:

1. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

2. **Procesar los datos crudos**
   Ejecute el notebook `raw-to-dataset.ipynb` para transformar `RawData.xlsx` en `salida_extendidafull3.csv`.

3. **Entrenar el modelo**
   Ejecute `eda-model-pi.ipynb` para realizar el EDA, entrenar el modelo y guardar `best_model_v1.joblib`.

4. **Iniciar la aplicaci√≥n**
   ```bash
   streamlit run app.py
   ```

   Al iniciar la app, cargue un archivo que tenga las mismas columnas con las que se entren√≥ el modelo.

5. **Despliegue en Streamlit Cloud (opcional)**
   Este repositorio est√° listo para ser desplegado en [Streamlit¬†Cloud](https://share.streamlit.io/):
   - Conecte su cuenta de GitHub.
   - Seleccione este repositorio.
   - Defina `app.py` como archivo principal.
   - La plataforma instalar√° las dependencias y cargar√° el modelo autom√°ticamente.

---

## üß† Notas y buenas pr√°cticas

- Antes de entrenar un nuevo modelo, actualice y ejecute por completo los notebooks.
- Aseg√∫rese de que el archivo de entrada usado en la app contenga exactamente las columnas con las que se entren√≥ el modelo; de lo contrario, se producir√° un error de validaci√≥n.
- Mantenga el nombre del modelo coherente (`best_model_vX.joblib`). Si se crea una nueva versi√≥n, actualice el nombre y el c√≥digo de carga en `app.py`.
- Bloquee versiones espec√≠ficas de librer√≠as en `requirements.txt` para asegurar la reproducibilidad.
- Para reproducir los gr√°ficos de EDA o personalizar la app, modifique directamente los notebooks y `app.py`.

---

